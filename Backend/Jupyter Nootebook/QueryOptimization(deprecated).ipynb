{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsPyIrdrP2IK",
        "outputId": "79d15607-610e-46d0-9c50-353bebfdb929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Queries:\n",
            " [[1, 4, 2, 13, 3, 14, 7, 25], [1, 15, 16, 2, 17, 3, 8, 9, 26], [1, 4, 2, 18, 3, 10, 7, 27], [1, 19, 11, 2, 20, 3, 8, 9, 28], [1, 4, 2, 21, 3, 12, 22, 29]]\n",
            "\n",
            "Tokenized Optimized Queries:\n",
            " [[1, 4, 2, 13, 3, 14, 7, 30, 5, 6, 31, 23], [1, 15, 16, 2, 17, 3, 8, 9, 32, 5, 6, 33], [1, 4, 2, 18, 3, 10, 7, 34, 5, 6, 10, 24], [1, 19, 11, 2, 20, 3, 8, 9, 35, 5, 6, 11, 24], [1, 4, 2, 21, 3, 12, 22, 36, 5, 6, 12, 23]]\n",
            "\n",
            "Padded Queries:\n",
            " [[ 1  4  2 13  3 14  7 25  0  0  0  0  0]\n",
            " [ 1 15 16  2 17  3  8  9 26  0  0  0  0]\n",
            " [ 1  4  2 18  3 10  7 27  0  0  0  0  0]\n",
            " [ 1 19 11  2 20  3  8  9 28  0  0  0  0]\n",
            " [ 1  4  2 21  3 12 22 29  0  0  0  0  0]]\n",
            "\n",
            "Padded Optimized Queries:\n",
            " [[ 1  4  2 13  3 14  7 30  5  6 31 23  0]\n",
            " [ 1 15 16  2 17  3  8  9 32  5  6 33  0]\n",
            " [ 1  4  2 18  3 10  7 34  5  6 10 24  0]\n",
            " [ 1 19 11  2 20  3  8  9 35  5  6 11 24]\n",
            " [ 1  4  2 21  3 12 22 36  5  6 12 23  0]]\n",
            "\n",
            "Vocabulary Size: 37\n",
            "\n",
            "Max Sequence Length: 13\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "queries = [\n",
        "    'SELECT * FROM users WHERE age > 18;',\n",
        "    'SELECT name, email FROM customers WHERE country = \"USA\";',\n",
        "    'SELECT * FROM products WHERE price > 100;',\n",
        "    'SELECT city, population FROM cities WHERE country = \"Canada\";',\n",
        "    'SELECT * FROM orders WHERE date >= \"2022-01-01\";',\n",
        "]\n",
        "\n",
        "optimized_queries = [\n",
        "    'SELECT * FROM users WHERE age > 18 ORDER BY name ASC;',\n",
        "    'SELECT name, email FROM customers WHERE country = \"USA\" ORDER BY name;',\n",
        "    'SELECT * FROM products WHERE price > 100 ORDER BY price DESC;',\n",
        "    'SELECT city, population FROM cities WHERE country = \"Canada\" ORDER BY population DESC;',\n",
        "    'SELECT * FROM orders WHERE date >= \"2022-01-01\" ORDER BY date ASC;',\n",
        "]\n",
        "\n",
        "all_texts = queries + optimized_queries\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(filters='')\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "# Vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Tokenize queries and optimized_queries\n",
        "tokenized_queries = tokenizer.texts_to_sequences(queries)\n",
        "tokenized_optimized_queries = tokenizer.texts_to_sequences(optimized_queries)\n",
        "\n",
        "max_len = max(max(len(seq) for seq in tokenized_queries), max(len(seq) for seq in tokenized_optimized_queries))\n",
        "padded_queries = pad_sequences(tokenized_queries, padding='post', maxlen=max_len)\n",
        "padded_optimized_queries = pad_sequences(tokenized_optimized_queries, padding='post', maxlen=max_len)\n",
        "\n",
        "input_data = tf.convert_to_tensor(padded_queries)\n",
        "output_data = tf.convert_to_tensor(padded_optimized_queries)\n",
        "\n",
        "print(\"Tokenized Queries:\\n\", tokenized_queries)\n",
        "print(\"\\nTokenized Optimized Queries:\\n\", tokenized_optimized_queries)\n",
        "print(\"\\nPadded Queries:\\n\", padded_queries)\n",
        "print(\"\\nPadded Optimized Queries:\\n\", padded_optimized_queries)\n",
        "print(\"\\nVocabulary Size:\", vocab_size)\n",
        "print(\"\\nMax Sequence Length:\", max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the model architecture\n",
        "def build_sequence_to_sequence_model(vocab_size, max_len):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(max_len,))\n",
        "    encoder_embedding = Embedding(vocab_size, 64, input_length=max_len, mask_zero=True)(encoder_inputs)\n",
        "    encoder_lstm, state_h, state_c = LSTM(64, return_state=True)(encoder_embedding)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(max_len,))\n",
        "    decoder_embedding = Embedding(vocab_size, 64, input_length=max_len, mask_zero=True)(decoder_inputs)\n",
        "    decoder_lstm = LSTM(64, return_sequences=True, return_state=True)\n",
        "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # Model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "    return model\n",
        "\n",
        "model = build_sequence_to_sequence_model(vocab_size, max_len)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "input_train_np, input_test_np, output_train_np, output_test_np = train_test_split(\n",
        "    input_data.numpy(), output_data.numpy(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert NumPy arrays back to TensorFlow tensors\n",
        "input_train = tf.convert_to_tensor(input_train_np)\n",
        "input_test = tf.convert_to_tensor(input_test_np)\n",
        "output_train = tf.convert_to_tensor(output_train_np)\n",
        "output_test = tf.convert_to_tensor(output_test_np)\n",
        "\n",
        "# Train the model\n",
        "model.fit([input_train, input_train], output_train, epochs=50, batch_size=1, validation_data=([input_test, input_test], output_test))\n",
        "\n",
        "evaluation_result = model.evaluate([input_test, input_test], output_test, batch_size=1)\n",
        "\n",
        "print(\"Evaluation Loss:\", evaluation_result[0])\n",
        "print(\"Evaluation Accuracy:\", evaluation_result[1])\n",
        "\n",
        "predictions = model.predict([input_test, input_test], batch_size=1)\n",
        "\n",
        "for i in range(min(3, len(predictions))):\n",
        "    print(\"\\nExample\", i + 1)\n",
        "    print(\"Predicted Sequence:\", predictions[i])\n",
        "    print(\"Actual Output:\", output_test[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMo1DI1UXCrL",
        "outputId": "fd357418-f9d1-4296-b60d-aaaf69fba2b4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_28\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_57 (InputLayer)       [(None, 13)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_58 (InputLayer)       [(None, 13)]                 0         []                            \n",
            "                                                                                                  \n",
            " embedding_56 (Embedding)    (None, 13, 64)               2368      ['input_57[0][0]']            \n",
            "                                                                                                  \n",
            " embedding_57 (Embedding)    (None, 13, 64)               2368      ['input_58[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_56 (LSTM)              [(None, 64),                 33024     ['embedding_56[0][0]']        \n",
            "                              (None, 64),                                                         \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " lstm_57 (LSTM)              [(None, 13, 64),             33024     ['embedding_57[0][0]',        \n",
            "                              (None, 64),                            'lstm_56[0][1]',             \n",
            "                              (None, 64)]                            'lstm_56[0][2]']             \n",
            "                                                                                                  \n",
            " dense_28 (Dense)            (None, 13, 37)               2405      ['lstm_57[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 73189 (285.89 KB)\n",
            "Trainable params: 73189 (285.89 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 10s 733ms/step - loss: 3.6095 - accuracy: 0.0606 - val_loss: 3.5970 - val_accuracy: 0.2222\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.5875 - accuracy: 0.2424 - val_loss: 3.5865 - val_accuracy: 0.2222\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.5631 - accuracy: 0.2727 - val_loss: 3.5728 - val_accuracy: 0.3333\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 3.5302 - accuracy: 0.2727 - val_loss: 3.5520 - val_accuracy: 0.3333\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 3.4726 - accuracy: 0.2727 - val_loss: 3.5151 - val_accuracy: 0.3333\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.3676 - accuracy: 0.2727 - val_loss: 3.4489 - val_accuracy: 0.3333\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 3.1611 - accuracy: 0.2727 - val_loss: 3.3575 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.8717 - accuracy: 0.2424 - val_loss: 3.3973 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.6753 - accuracy: 0.2424 - val_loss: 3.5033 - val_accuracy: 0.3333\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.5470 - accuracy: 0.3636 - val_loss: 3.5229 - val_accuracy: 0.3333\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 2.4316 - accuracy: 0.3636 - val_loss: 3.5545 - val_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 2.3527 - accuracy: 0.4242 - val_loss: 3.6062 - val_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 2.2695 - accuracy: 0.4545 - val_loss: 3.6087 - val_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 2.1956 - accuracy: 0.4545 - val_loss: 3.6234 - val_accuracy: 0.3333\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.1301 - accuracy: 0.4545 - val_loss: 3.6320 - val_accuracy: 0.3333\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.0649 - accuracy: 0.4545 - val_loss: 3.6563 - val_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 2.0042 - accuracy: 0.4545 - val_loss: 3.6736 - val_accuracy: 0.3333\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.9469 - accuracy: 0.4545 - val_loss: 3.6931 - val_accuracy: 0.3333\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.8910 - accuracy: 0.4545 - val_loss: 3.7239 - val_accuracy: 0.3333\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.8375 - accuracy: 0.4848 - val_loss: 3.7464 - val_accuracy: 0.3333\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.7906 - accuracy: 0.5455 - val_loss: 3.7570 - val_accuracy: 0.3333\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 1.7384 - accuracy: 0.5455 - val_loss: 3.7480 - val_accuracy: 0.3333\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.6856 - accuracy: 0.5455 - val_loss: 3.7604 - val_accuracy: 0.3333\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 1.6331 - accuracy: 0.5758 - val_loss: 3.7734 - val_accuracy: 0.3333\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.5864 - accuracy: 0.5758 - val_loss: 3.7549 - val_accuracy: 0.3333\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.5348 - accuracy: 0.5758 - val_loss: 3.7996 - val_accuracy: 0.3333\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.4933 - accuracy: 0.5758 - val_loss: 3.8003 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.4398 - accuracy: 0.5758 - val_loss: 3.7794 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.3900 - accuracy: 0.5758 - val_loss: 3.8041 - val_accuracy: 0.3333\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 1.3441 - accuracy: 0.5758 - val_loss: 3.7842 - val_accuracy: 0.3333\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.2927 - accuracy: 0.5758 - val_loss: 3.7770 - val_accuracy: 0.3333\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.2522 - accuracy: 0.6061 - val_loss: 3.7790 - val_accuracy: 0.3333\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.2031 - accuracy: 0.6667 - val_loss: 3.7626 - val_accuracy: 0.3333\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 1.1532 - accuracy: 0.6667 - val_loss: 3.7815 - val_accuracy: 0.3333\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 1.1108 - accuracy: 0.6970 - val_loss: 3.7647 - val_accuracy: 0.3333\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.0613 - accuracy: 0.7576 - val_loss: 3.7431 - val_accuracy: 0.3333\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 1.0152 - accuracy: 0.8788 - val_loss: 3.7581 - val_accuracy: 0.3333\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.9722 - accuracy: 0.8788 - val_loss: 3.7355 - val_accuracy: 0.3333\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.9278 - accuracy: 0.8788 - val_loss: 3.7165 - val_accuracy: 0.4444\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.8856 - accuracy: 0.8788 - val_loss: 3.7044 - val_accuracy: 0.4444\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.8482 - accuracy: 0.8788 - val_loss: 3.6859 - val_accuracy: 0.4444\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.8107 - accuracy: 0.9091 - val_loss: 3.6648 - val_accuracy: 0.4444\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.7718 - accuracy: 0.9394 - val_loss: 3.6586 - val_accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7344 - accuracy: 0.9697 - val_loss: 3.6461 - val_accuracy: 0.4444\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.7029 - accuracy: 0.9697 - val_loss: 3.6296 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6679 - accuracy: 0.9697 - val_loss: 3.6127 - val_accuracy: 0.4444\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6348 - accuracy: 0.9697 - val_loss: 3.6081 - val_accuracy: 0.4444\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6063 - accuracy: 1.0000 - val_loss: 3.6044 - val_accuracy: 0.4444\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5780 - accuracy: 1.0000 - val_loss: 3.5849 - val_accuracy: 0.4444\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5505 - accuracy: 1.0000 - val_loss: 3.5750 - val_accuracy: 0.5556\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 3.5750 - accuracy: 0.5556\n",
            "Evaluation Loss: 3.5750303268432617\n",
            "Evaluation Accuracy: 0.5555555820465088\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "\n",
            "Example 1\n",
            "Predicted Sequence: [[1.18839525e-04 9.32903230e-01 4.34387155e-04 1.17402487e-04\n",
            "  2.48279534e-02 1.06802225e-04 2.33537157e-05 5.83801411e-05\n",
            "  1.46910927e-04 9.02155007e-05 2.75692175e-04 4.78881039e-03\n",
            "  2.08255238e-04 1.04305136e-03 3.30926676e-04 7.75169392e-05\n",
            "  5.15600623e-05 1.37167895e-04 1.21271238e-03 2.99189389e-02\n",
            "  5.09403006e-04 1.07767095e-03 8.97097489e-05 1.24369355e-04\n",
            "  8.15609237e-05 1.68272687e-04 5.02375879e-05 5.68249452e-05\n",
            "  1.00920151e-04 1.02294558e-04 6.51876617e-05 1.02338956e-04\n",
            "  9.17283069e-06 2.59718945e-04 9.96474046e-05 1.51215296e-04\n",
            "  7.94574371e-05]\n",
            " [7.60400959e-04 1.58282354e-01 2.36132294e-02 1.82330445e-03\n",
            "  3.50798160e-01 5.27837721e-04 3.82885424e-04 9.56282485e-04\n",
            "  1.27716875e-03 6.87336957e-04 3.90331284e-03 1.16952464e-01\n",
            "  2.56333989e-03 1.44031467e-02 3.96478642e-03 5.11176244e-04\n",
            "  3.89880181e-04 1.64524314e-03 9.47453175e-03 2.70928353e-01\n",
            "  8.18580575e-03 1.52824521e-02 8.31503246e-04 7.20391283e-04\n",
            "  8.82881752e-04 8.99580074e-04 5.61243796e-04 3.28353024e-04\n",
            "  4.20213706e-04 1.36633893e-03 7.73326668e-04 5.88772527e-04\n",
            "  2.73698533e-04 6.39396079e-04 3.46952002e-03 4.79628943e-04\n",
            "  4.51622822e-04]\n",
            " [3.30236246e-04 1.05099678e-02 3.22172701e-01 6.17036689e-03\n",
            "  1.48075253e-01 4.44513280e-04 5.46243682e-04 2.46346113e-03\n",
            "  3.78598250e-03 1.03288784e-03 8.36910121e-03 2.07366854e-01\n",
            "  4.73678391e-03 4.28881831e-02 7.74047617e-03 4.99738730e-04\n",
            "  4.96149121e-04 1.55349437e-03 2.95660738e-02 8.08954760e-02\n",
            "  4.54344042e-02 5.74319325e-02 1.91636861e-03 3.89267050e-04\n",
            "  6.65177649e-04 9.94216884e-04 6.71288813e-04 3.00788495e-04\n",
            "  3.09820985e-04 1.38402230e-03 1.52974296e-03 7.74406595e-04\n",
            "  5.56849525e-04 4.16639232e-04 6.28477847e-03 5.18252375e-04\n",
            "  7.78134388e-04]\n",
            " [4.38590578e-05 7.05739949e-04 7.58000255e-01 1.75921787e-02\n",
            "  1.40913948e-02 1.33035588e-04 1.18668184e-04 1.91301957e-03\n",
            "  2.47433665e-03 8.07236822e-04 4.40753391e-03 1.72306616e-02\n",
            "  3.51709547e-03 1.68196000e-02 4.69419686e-03 1.09495239e-04\n",
            "  1.00214354e-04 3.19432351e-04 2.93479431e-02 3.75503651e-03\n",
            "  6.90379515e-02 4.87473980e-02 2.00414192e-03 5.63118519e-05\n",
            "  8.85421614e-05 2.49591394e-04 1.26375482e-04 3.80486199e-05\n",
            "  5.74332371e-05 2.17844528e-04 7.92276347e-04 1.77383728e-04\n",
            "  1.67592676e-04 8.37894258e-05 1.22741761e-03 2.29958488e-04\n",
            "  5.17021399e-04]\n",
            " [1.10698995e-04 1.14990573e-03 3.30590419e-02 3.76281828e-01\n",
            "  3.58687807e-03 2.42464230e-04 1.30695102e-04 1.80020127e-02\n",
            "  1.60889924e-02 8.01306125e-03 2.68972460e-02 1.31791169e-02\n",
            "  3.07825841e-02 3.47975753e-02 3.25777903e-02 8.35795872e-05\n",
            "  1.36136368e-04 4.16632916e-04 7.23682195e-02 5.34880813e-03\n",
            "  2.02072427e-01 9.83306915e-02 1.09193828e-02 7.86274031e-05\n",
            "  1.19747805e-04 5.25598589e-04 2.22245100e-04 7.25356804e-05\n",
            "  2.01050643e-04 1.75575857e-04 4.83674044e-03 1.78725226e-04\n",
            "  1.58146504e-04 1.45066922e-04 3.31257167e-03 2.51099980e-03\n",
            "  2.88641918e-03]\n",
            " [4.73485670e-05 4.78249422e-04 1.28977746e-03 7.86167860e-01\n",
            "  5.34852094e-04 8.16695829e-05 4.97788933e-05 3.35650072e-02\n",
            "  1.99924130e-02 9.58217587e-03 2.10846178e-02 3.00155208e-03\n",
            "  3.57686467e-02 6.13940042e-03 2.28081401e-02 3.80799429e-05\n",
            "  6.38283673e-05 1.36043745e-04 8.86194129e-03 9.28631751e-04\n",
            "  1.29966456e-02 9.45158768e-03 1.45067805e-02 3.53410651e-05\n",
            "  7.11592584e-05 1.38397008e-04 1.20890007e-04 3.22876840e-05\n",
            "  8.47143092e-05 6.83257895e-05 4.21233103e-03 8.49761491e-05\n",
            "  7.50155086e-05 6.56008269e-05 1.77583040e-03 3.28435609e-03\n",
            "  2.37571658e-03]\n",
            " [5.86111390e-04 2.10834271e-03 6.74902520e-04 2.33018436e-02\n",
            "  8.09750578e-04 6.03277353e-04 2.82311492e-04 6.31937310e-02\n",
            "  3.23006004e-01 1.27390072e-01 5.79785965e-02 6.76983735e-03\n",
            "  9.19908360e-02 6.77210279e-03 3.50476354e-02 2.41773378e-04\n",
            "  3.86564876e-04 5.45067422e-04 1.63623318e-02 1.45097100e-03\n",
            "  1.03792790e-02 1.16549945e-02 9.03090388e-02 3.54564632e-04\n",
            "  4.48698585e-04 5.14711719e-04 6.66729000e-04 4.49961430e-04\n",
            "  6.28436450e-04 3.41491250e-04 3.88428569e-02 5.21613052e-04\n",
            "  3.70626891e-04 2.91178731e-04 1.84998978e-02 3.21884379e-02\n",
            "  3.40353139e-02]\n",
            " [1.32903969e-03 2.71345605e-03 2.15609762e-04 1.18921101e-02\n",
            "  4.54438326e-04 1.44740008e-03 6.61721104e-04 5.27661927e-02\n",
            "  5.60075119e-02 2.88081825e-01 7.43459864e-03 3.07795079e-03\n",
            "  1.89004540e-02 4.96694725e-03 1.41261574e-02 7.14653695e-04\n",
            "  1.02208403e-03 9.60969890e-04 1.05704013e-02 1.99812371e-03\n",
            "  4.09205584e-03 5.24527160e-03 4.32429239e-02 8.44147871e-04\n",
            "  7.55037065e-04 1.29461999e-03 1.31263421e-03 1.01613416e-03\n",
            "  1.46686158e-03 1.09520159e-03 1.05442524e-01 1.16297929e-03\n",
            "  8.58454208e-04 1.28136028e-03 2.35780012e-02 2.80918330e-01\n",
            "  4.70518246e-02]\n",
            " [2.60558631e-03 4.15651454e-03 3.92501475e-04 8.78755469e-03\n",
            "  1.09318725e-03 3.19796498e-03 1.68961531e-03 3.27653401e-02\n",
            "  2.77727060e-02 1.32961437e-01 4.35737753e-03 4.05869586e-03\n",
            "  9.61554423e-03 5.51857613e-03 1.12670157e-02 2.30008201e-03\n",
            "  2.54145893e-03 2.07823934e-03 8.09505768e-03 3.65534215e-03\n",
            "  4.24718391e-03 5.02152508e-03 2.48673409e-02 2.10315525e-03\n",
            "  1.47490087e-03 3.37669672e-03 2.64255656e-03 2.12657196e-03\n",
            "  3.63326259e-03 2.67725298e-03 1.25951797e-01 3.12780426e-03\n",
            "  1.94434007e-03 3.82379419e-03 4.36437204e-02 4.44763094e-01\n",
            "  5.56652732e-02]\n",
            " [2.60558631e-03 4.15651454e-03 3.92501475e-04 8.78755469e-03\n",
            "  1.09318725e-03 3.19796498e-03 1.68961531e-03 3.27653401e-02\n",
            "  2.77727060e-02 1.32961437e-01 4.35737753e-03 4.05869586e-03\n",
            "  9.61554423e-03 5.51857613e-03 1.12670157e-02 2.30008201e-03\n",
            "  2.54145893e-03 2.07823934e-03 8.09505768e-03 3.65534215e-03\n",
            "  4.24718391e-03 5.02152508e-03 2.48673409e-02 2.10315525e-03\n",
            "  1.47490087e-03 3.37669672e-03 2.64255656e-03 2.12657196e-03\n",
            "  3.63326259e-03 2.67725298e-03 1.25951797e-01 3.12780426e-03\n",
            "  1.94434007e-03 3.82379419e-03 4.36437204e-02 4.44763094e-01\n",
            "  5.56652732e-02]\n",
            " [2.60558631e-03 4.15651454e-03 3.92501475e-04 8.78755469e-03\n",
            "  1.09318725e-03 3.19796498e-03 1.68961531e-03 3.27653401e-02\n",
            "  2.77727060e-02 1.32961437e-01 4.35737753e-03 4.05869586e-03\n",
            "  9.61554423e-03 5.51857613e-03 1.12670157e-02 2.30008201e-03\n",
            "  2.54145893e-03 2.07823934e-03 8.09505768e-03 3.65534215e-03\n",
            "  4.24718391e-03 5.02152508e-03 2.48673409e-02 2.10315525e-03\n",
            "  1.47490087e-03 3.37669672e-03 2.64255656e-03 2.12657196e-03\n",
            "  3.63326259e-03 2.67725298e-03 1.25951797e-01 3.12780426e-03\n",
            "  1.94434007e-03 3.82379419e-03 4.36437204e-02 4.44763094e-01\n",
            "  5.56652732e-02]\n",
            " [2.60558631e-03 4.15651454e-03 3.92501475e-04 8.78755469e-03\n",
            "  1.09318725e-03 3.19796498e-03 1.68961531e-03 3.27653401e-02\n",
            "  2.77727060e-02 1.32961437e-01 4.35737753e-03 4.05869586e-03\n",
            "  9.61554423e-03 5.51857613e-03 1.12670157e-02 2.30008201e-03\n",
            "  2.54145893e-03 2.07823934e-03 8.09505768e-03 3.65534215e-03\n",
            "  4.24718391e-03 5.02152508e-03 2.48673409e-02 2.10315525e-03\n",
            "  1.47490087e-03 3.37669672e-03 2.64255656e-03 2.12657196e-03\n",
            "  3.63326259e-03 2.67725298e-03 1.25951797e-01 3.12780426e-03\n",
            "  1.94434007e-03 3.82379419e-03 4.36437204e-02 4.44763094e-01\n",
            "  5.56652732e-02]\n",
            " [2.60558771e-03 4.15651267e-03 3.92501650e-04 8.78755283e-03\n",
            "  1.09318772e-03 3.19796638e-03 1.68961531e-03 3.27653326e-02\n",
            "  2.77727060e-02 1.32961467e-01 4.35737940e-03 4.05869586e-03\n",
            "  9.61554423e-03 5.51857613e-03 1.12670157e-02 2.30008340e-03\n",
            "  2.54146010e-03 2.07823934e-03 8.09505768e-03 3.65534215e-03\n",
            "  4.24718391e-03 5.02152508e-03 2.48673409e-02 2.10315525e-03\n",
            "  1.47490087e-03 3.37669509e-03 2.64255656e-03 2.12657196e-03\n",
            "  3.63326259e-03 2.67725158e-03 1.25951782e-01 3.12780426e-03\n",
            "  1.94434007e-03 3.82379419e-03 4.36437204e-02 4.44763094e-01\n",
            "  5.56652732e-02]]\n",
            "Actual Output: tf.Tensor([ 1 15 16  2 17  3  8  9 32  5  6 33  0], shape=(13,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_optimized_query(new_query, tokenizer, model, max_len):\n",
        "    tokenized_new_query = tokenizer.texts_to_sequences([new_query])\n",
        "    padded_new_query = pad_sequences(tokenized_new_query, padding='post', maxlen=max_len)\n",
        "\n",
        "    prediction = model.predict([padded_new_query, padded_new_query], batch_size=1)\n",
        "\n",
        "    predicted_sequence = np.argmax(prediction, axis=-1)[0]\n",
        "    predicted_query = tokenizer.sequences_to_texts([predicted_sequence])[0]\n",
        "\n",
        "    return predicted_query\n",
        "\n",
        "new_query = 'SELECT age, name FROM users WHERE country = \"France\";'\n",
        "predicted_optimized_query = predict_optimized_query(new_query, tokenizer, model, max_len)\n",
        "\n",
        "print(\"Input Query:\", new_query)\n",
        "print(\"Predicted Optimized Query:\", predicted_optimized_query)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejfKHqc4cGXd",
        "outputId": "348c8fe1-3ace-41ab-c8a3-80f6a1feb7d8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 134ms/step\n",
            "Input Query: SELECT age, name FROM users WHERE country = \"France\";\n",
            "Predicted Optimized Query: select * from where where country \"canada\" \"canada\" \"canada\" \"canada\" \"canada\" \"canada\" \"canada\"\n"
          ]
        }
      ]
    }
  ]
}